{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11befc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.6 2.7.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import os,math,time,random,warnings\n",
    "from dataclasses import dataclass\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import FrEIA.framework as Ff\n",
    "import FrEIA.modules as Fm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(np.__version__, torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87009602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "PyTorch version: 2.7.1+cu118 with CUDA = True\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__, \"with CUDA =\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98402c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"mvtec_anomaly_detection\"\n",
    "class_name = \"bottle\"\n",
    "encoder_architecture = \"wide_resnet50_2\"  # \"resnet18\"\n",
    "input_size = 256\n",
    "batch_size = 8\n",
    "\n",
    "epoches = 1\n",
    "workers = 0\n",
    "learning_rate = 2e-4\n",
    "\n",
    "coupling_blocks = 8\n",
    "condition_dim =128\n",
    "clamp_alpha = 1.9\n",
    "seed=42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f480df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVTEC_Dataset(Dataset):\n",
    "    def __init__(self, data_path, class_name, is_train=True, resize=256,\n",
    "                 cropsize=256):\n",
    "        self.data_path = data_path\n",
    "        self.class_name = class_name\n",
    "        self.is_train = is_train\n",
    "        self.resize = resize\n",
    "        self.cropsize = cropsize\n",
    "        self.x, self.y ,self.mask = self._gather()\n",
    "        self.t_img = T.Compose([\n",
    "            T.Resize(resize,interpolation=Image.Resampling.LANCZOS),\n",
    "            T.CenterCrop(cropsize),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.t_mask = T.Compose([\n",
    "            T.Resize(resize,interpolation=Image.Resampling.NEAREST),\n",
    "            T.CenterCrop(cropsize),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def _gather(self):\n",
    "        phase = \"train\" if self.is_train else \"test\"\n",
    "        img_dir = os.path.join(self.data_path, self.class_name, phase) \n",
    "        gt_dir = os.path.join(self.data_path, self.class_name, \"ground_truth\")\n",
    "        x,y,mask = [],[],[]\n",
    "        for fname in os.listdir(img_dir):\n",
    "            tdir = os.path.join(img_dir, fname)\n",
    "            if not os.path.isdir(img_dir):continue\n",
    "            files = sorted([os.path.join(tdir,f) for f in os.listdir(tdir) if f.endswith('.png')])\n",
    "            x.extend(files)\n",
    "            if fname==\"good\":\n",
    "                y.extend([0]*len(files))\n",
    "                mask.extend([None]*len(files))\n",
    "            else:\n",
    "                y.extend([1]*len(files))\n",
    "                gt_tdir= os.path.join(gt_dir, fname)\n",
    "                base=[os.path.splitext(os.path.basename(f))[0] for f in files]\n",
    "                mask.extend([os.path.join(gt_tdir,b+\"_mask.png\") for b in base])\n",
    "        assert len(x)==len(y)\n",
    "        return x,y,mask\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        img=Image.open(self.x[idx]).convert(\"RGB\")\n",
    "        img=self.t_img(img)\n",
    "        if self.y[idx]==0:\n",
    "            mask=torch.zeros(1,self.cropsize,self.cropsize)\n",
    "        else:\n",
    "            mask=Image.open(self.mask[idx])\n",
    "            mask=self.t_mask(mask)\n",
    "        return img,self.y[idx],mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "608404e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True; torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seeds(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80af3094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 209\n",
      "Train Batches : 26\n"
     ]
    }
   ],
   "source": [
    "train_ds=MVTEC_Dataset(data_path, class_name, is_train=True, resize=input_size, cropsize=input_size)\n",
    "print(\"Number of training samples:\", len(train_ds))\n",
    "print(\"Train Batches :\", len(train_ds)//batch_size)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b25b4d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 83\n",
      "Test Batches : 10\n"
     ]
    }
   ],
   "source": [
    "test_ds=MVTEC_Dataset(data_path, class_name, is_train=False, resize=input_size, cropsize=input_size)\n",
    "print(\"Number of test samples:\", len(test_ds))\n",
    "print(\"Test Batches :\", len(test_ds)//batch_size)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a604cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subnet_fc(dims_in, dims_out):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dims_in, 2*dims_in),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(2*dims_in, dims_out)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "411dbb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cflow_head(n_feat,condition_dim,coupling_blocks,clamp_alpha):\n",
    "    coder=Ff.SequenceINN(n_feat)\n",
    "    for _ in range(coupling_blocks):\n",
    "                coder.append(Fm.AllInOneBlock, cond=0, cond_shape=(condition_dim,),\n",
    "                    subnet_constructor=subnet_fc, affine_clamping=clamp_alpha,\n",
    "                    global_affine_type='SOFTPLUS', permute_soft=False)\n",
    "    return coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7269c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encoder(arch,pool_layers):\n",
    "    acts={}\n",
    "    def hook(name):\n",
    "        def fn(module, input, output):\n",
    "            acts[name] = output.detach()\n",
    "        return fn\n",
    "    \n",
    "    if arch==\"resnet18\":\n",
    "        encoder=models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        layers=[encoder.layer2,encoder.layer3,encoder.layer4]\n",
    "        dims=[encoder.layer2[-1].conv2.out_channels,\n",
    "              encoder.layer3[-1].conv2.out_channels,\n",
    "              encoder.layer4[-1].conv2.out_channels]\n",
    "    elif arch==\"wide_resnet50_2\":\n",
    "        encoder=models.wide_resnet50_2(weights=models.Wide_ResNet50_2_Weights.DEFAULT)\n",
    "        layers=[encoder.layer2,encoder.layer3,encoder.layer4]\n",
    "        dims=[encoder.layer2[-1].conv3.out_channels,\n",
    "              encoder.layer3[-1].conv3.out_channels,\n",
    "              encoder.layer4[-1].conv3.out_channels]\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Encoder architecture {arch} not implemented\")\n",
    "    L=min(len(pool_layers),len(layers))\n",
    "    for i in range(L):\n",
    "        layers[i].register_forward_hook(hook(pool_layers[i]))\n",
    "    return encoder.eval(),pool_layers[:L], dims[:L], acts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "49bb75ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_layers=['l0','l1','l2']\n",
    "encoder,pool_layers,pool_dims,acts=load_encoder(encoder_architecture,pool_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c062f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.to(device).eval()\n",
    "decoders=[]\n",
    "for d in pool_dims:\n",
    "    decoder=cflow_head(d,condition_dim,coupling_blocks,clamp_alpha)\n",
    "    decoder.to(device)\n",
    "    decoders.append(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2bb2b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in encoder.parameters():\n",
    "    p.requires_grad=False\n",
    "optim=torch.optim.Adam(\n",
    "    [p for decoder in decoders for p in decoder.parameters()],\n",
    "    lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2eb7439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positionalencoding2d(D, H, W):\n",
    "    if D % 4 != 0:\n",
    "        raise ValueError(\"positionalencoding2d: D must be divisible by 4\")\n",
    "    pe = torch.zeros(D, H, W)\n",
    "    half = D // 2\n",
    "    div_term = torch.exp(torch.arange(0., half, 2) * -(math.log(10000.0) / half))\n",
    "    pos_w = torch.arange(0., W).unsqueeze(1)\n",
    "    pos_h = torch.arange(0., H).unsqueeze(1)\n",
    "    pe[0:half:2, :, :] = torch.sin(pos_w * div_term).T.unsqueeze(1).repeat(1, H, 1)\n",
    "    pe[1:half:2, :, :] = torch.cos(pos_w * div_term).T.unsqueeze(1).repeat(1, H, 1)\n",
    "    pe[half::2, :, :]  = torch.sin(pos_h * div_term).T.unsqueeze(2).repeat(1, 1, W)\n",
    "    pe[half+1::2, :, :] = torch.cos(pos_h * div_term).T.unsqueeze(2).repeat(1, 1, W)\n",
    "    return pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f3c094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_nll_logprob(z, log_jac_det):\n",
    "    k = z.size(1)\n",
    "    const = -0.5 * k * torch.log(torch.tensor(2 * math.pi, device=z.device, dtype=z.dtype))\n",
    "    quad = -0.5 * torch.sum(z**2, dim=1)\n",
    "    return const + quad + log_jac_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "343bc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(encoder,decoders,loader,optim,device,pool_layers,acts,P):\n",
    "    for d in decoders:\n",
    "        d.train()\n",
    "    \n",
    "    total_loss=0.0\n",
    "    total_B=0\n",
    "    log_sigomoid=nn.LogSigmoid()\n",
    "    N=256\n",
    "    for imgs,_,_ in tqdm(loader,desc=\"Training\"):\n",
    "        images=imgs.to(device)\n",
    "        optim.zero_grad()\n",
    "        with torch.no_grad():_=encoder(images)\n",
    "        loss_sum=0.0\n",
    "        for l,name in enumerate(pool_layers):\n",
    "            feat=acts[name]\n",
    "            B,C,H,W=feat.size()\n",
    "            S=H*W\n",
    "            E=B*S\n",
    "            p=positionalencoding2d(P,H,W).to(device).unsqueeze(0).repeat(B,1,1,1)\n",
    "            c_r=p.reshape(B,P,H,W).transpose(1,2).reshape(E,P)\n",
    "            e_r = feat.reshape(B,C,S).transpose(1,2).reshape(E,C)\n",
    "            perm=torch.randperm(E,device=device)\n",
    "            a=max(1,E//N)\n",
    "            dec=decoders[l]\n",
    "            for f in range(a):\n",
    "                idx=torch.arange(f*N,min((f+1)*N,E),device=device)\n",
    "                if idx.numel()==0:\n",
    "                    continue\n",
    "                c_p=c_r[perm[idx]]\n",
    "                e_p=e_r[perm[idx]]\n",
    "                z,log_jac=dec(e_p, [c_p,])\n",
    "                log_prob=gaussian_nll_logprob(z, log_jac)/C\n",
    "                loss=-log_sigomoid(log_prob).sum()\n",
    "                loss_sum+=loss\n",
    "        loss_sum.backward()\n",
    "        optim.step()\n",
    "        total_loss+=loss_sum.item()\n",
    "        total_B+=images.size(0)\n",
    "    avg_loss=total_loss/max(1,total_B)\n",
    "    return avg_loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c4bb887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(encoder, decoders, loader, device, pool_layers, acts, P, cropsize, fraction: float = 1.0):\n",
    "    \n",
    "    for d in decoders: \n",
    "        d.eval()\n",
    "    heights, widths=[], []\n",
    "    dists=[[] for _ in pool_layers]\n",
    "    gt_label_list, gt_mask_list=[], []\n",
    "\n",
    "    total_batches=len(loader)\n",
    "    use_batches=max(1, int(math.ceil(total_batches * float(fraction))))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i,(images, labels, masks) in enumerate(tqdm(loader, desc='Test')):\n",
    "            if i>=use_batches: break\n",
    "            gt_label_list.extend(labels.numpy()); gt_mask_list.extend(masks.numpy())\n",
    "            images=images.to(device)\n",
    "            _=encoder(images)\n",
    "            for l,name in enumerate(pool_layers):\n",
    "                feet=acts[name]\n",
    "                B,C,H,W=feet.size(); S=H*W; E=B*S\n",
    "                if i==0: heights.append(H); widths.append(W)\n",
    "                p=positionalencoding2d(P, H, W).to(device).unsqueeze(0).repeat(B,1,1,1)\n",
    "                c_r=p.reshape(B,P,S).transpose(1,2).reshape(E,P)\n",
    "                e_r=feet.reshape(B,C,S).transpose(1,2).reshape(E,C)\n",
    "                dec=decoders[l]\n",
    "                z,log_jac = dec(e_r, [c_r,])\n",
    "                log_prob=gaussian_nll_logprob(z, log_jac) / C\n",
    "                dists[l].extend(log_prob.detach().cpu().tolist())\n",
    "    return heights, widths, dists, gt_label_list, gt_mask_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "753f6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_anomaly_map(dists, heights, widths, cropsize, pool_layers):\n",
    "    maps=[]\n",
    "    for l in range(len(pool_layers)):\n",
    "        t=torch.tensor(dists[l], dtype=torch.double)\n",
    "        t-=torch.max(t); prob = torch.exp(t)\n",
    "        m=prob.reshape(-1, heights[l], widths[l])\n",
    "        up=F.interpolate(m.unsqueeze(1), size=(cropsize,cropsize), mode='bilinear', align_corners=True).squeeze().numpy()\n",
    "        maps.append(up)\n",
    "    score=np.zeros_like(maps[0])\n",
    "    for m in maps:\n",
    "        score+=m\n",
    "    super_mask=score.max()-score\n",
    "    return super_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20ea67ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 26/26 [02:57<00:00,  6.82s/it]\n",
      "Test: 100%|██████████| 11/11 [01:05<00:00,  5.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1 - loss 2124.8467 - full-test AUROC 99.37%\n",
      "  ✓ Saved BEST to new models\\bottle\\best_cflow_ad.pt (AUROC 99.37%)\n",
      "Saved LAST to new models\\bottle\\last_cflow_ad.pt\n"
     ]
    }
   ],
   "source": [
    "history = {\"loss\": [], \"det_auroc_full\": []}\n",
    "ckpt_root = os.path.join(\"new models\", class_name)\n",
    "os.makedirs(ckpt_root, exist_ok=True)\n",
    "\n",
    "best_det_auroc = -1.0\n",
    "best_path = os.path.join(ckpt_root, \"best_cflow_ad.pt\")\n",
    "last_path = os.path.join(ckpt_root, \"last_cflow_ad.pt\")\n",
    "\n",
    "for epoch in range(1, epoches + 1):\n",
    "    loss=train_epoch(encoder, decoders, train_loader, optim, device, pool_layers, acts, condition_dim)\n",
    "    history[\"loss\"].append(loss)\n",
    "    heights, widths, dists, gt_label_list, gt_mask_list = test_epoch(\n",
    "        encoder, decoders, test_loader, device, pool_layers, acts, condition_dim, input_size, fraction=1.0\n",
    ")\n",
    "    super_mask = compute_anomaly_map(dists, heights, widths, input_size, pool_layers)\n",
    "    score_label = np.max(super_mask, axis=(1,2))\n",
    "    gt_label = np.asarray(gt_label_list, dtype=bool)\n",
    "    det_auroc = float(roc_auc_score(gt_label, score_label)*100)\n",
    "    history[\"det_auroc_full\"].append(det_auroc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epoches} - loss {loss:.4f} - full-test AUROC {det_auroc:.2f}%\")\n",
    "\n",
    "    state = {\n",
    "\n",
    "        \"encoder_arch\": encoder_architecture,\n",
    "        \"pool_layers\": pool_layers,\n",
    "        \"epoch\": (epoch+1),\n",
    "        \"model\": [d.state_dict() for d in decoders],\n",
    "        \"optimizer\": optim.state_dict(),\n",
    "        \"det_auroc_full\": det_auroc,\n",
    "    }\n",
    "\n",
    "    # Save best if improved\n",
    "    if det_auroc > best_det_auroc:\n",
    "        torch.save(state, best_path)\n",
    "        best_det_auroc = det_auroc\n",
    "        print(f\"  ✓ Saved BEST to {best_path} (AUROC {best_det_auroc:.2f}%)\")\n",
    "\n",
    "final_state = {\n",
    "    \"encoder_arch\": encoder_architecture,\n",
    "    \"pool_layers\": pool_layers,\n",
    "    \"epoch\": epoches,\n",
    "    \"model\": [d.state_dict() for d in decoders],\n",
    "    \"optimizer\": optim.state_dict(),\n",
    "    \"det_auroc_full\": history[\"det_auroc_full\"][-1] if history[\"det_auroc_full\"] else None,\n",
    "}\n",
    "torch.save(final_state, last_path)\n",
    "print(f\"Saved LAST to {last_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
