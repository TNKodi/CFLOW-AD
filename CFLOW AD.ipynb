{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11befc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,math,time,random,warnings\n",
    "from dataclasses import dataclass\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import FrEIA.framework as Ff\n",
    "import FrEIA.modules as Fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87009602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "PyTorch version: 2.7.1+cu118 with CUDA = True\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__, \"with CUDA =\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98402c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"mvtec_anomaly_detection\"\n",
    "class_name = \"bottle\"\n",
    "encoder_architecture = \"resnet18\"\n",
    "input_size = 256\n",
    "batch_size = 8\n",
    "\n",
    "epoches = 50\n",
    "workers = 4\n",
    "learning_rate = 1e-4\n",
    "\n",
    "coupling_blocks = 8\n",
    "condition_dim =128\n",
    "clamp_alpha = 1.9\n",
    "seed=42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f480df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVTEC_Dataset(Dataset):\n",
    "    def __init__(self, data_path, class_name, is_train=True, resize=256,\n",
    "                 cropsize=256):\n",
    "        self.data_path = data_path\n",
    "        self.class_name = class_name\n",
    "        self.is_train = is_train\n",
    "        self.resize = resize\n",
    "        self.cropsize = cropsize\n",
    "        self.x, self.y ,self.mask = self._gather()\n",
    "        self.t_img = T.Compose([\n",
    "            T.Resize(resize,interpolation=Image.Resampling.LANCZOS),\n",
    "            T.CenterCrop(cropsize),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.t_mask = T.Compose([\n",
    "            T.Resize(resize,interpolation=Image.Resampling.NEAREST),\n",
    "            T.CenterCrop(cropsize),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def _gather(self):\n",
    "        phase = \"train\" if self.is_train else \"test\"\n",
    "        img_dir = os.path.join(self.data_path, self.class_name, phase) \n",
    "        gt_dir = os.path.join(self.data_path, self.class_name, \"ground_truth\")\n",
    "        x,y,mask = [],[],[]\n",
    "        for fname in os.listdir(img_dir):\n",
    "            tdir = os.path.join(img_dir, fname)\n",
    "            if not os.path.isdir(img_dir):continue\n",
    "            files = sorted([os.path.join(tdir,f) for f in os.listdir(tdir) if f.endswith('.png')])\n",
    "            x.extend(files)\n",
    "            if fname==\"good\":\n",
    "                y.extend([0]*len(files))\n",
    "                mask.extend([None]*len(files))\n",
    "            else:\n",
    "                y.extend([1]*len(files))\n",
    "                gt_tdir= os.path.join(gt_dir, fname)\n",
    "                base=[os.path.splitext(os.path.basename(f))[0] for f in files]\n",
    "                mask.extend([os.path.join(gt_tdir,b+\"_mask.png\") for b in base])\n",
    "        assert len(x)==len(y)\n",
    "        return x,y,mask\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        img=Image.open(self.x[idx]).convert(\"RGB\")\n",
    "        img=self.t_img(img)\n",
    "        if self.y[idx]==0:\n",
    "            mask=torch.zeros(1,self.cropsize,self.cropsize)\n",
    "        else:\n",
    "            mask=Image.open(self.mask[idx])\n",
    "            mask=self.t_mask(mask)\n",
    "        return img,self.y[idx],mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "608404e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True; torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seeds(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80af3094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 209\n",
      "Train Batches : 26\n"
     ]
    }
   ],
   "source": [
    "train_ds=MVTEC_Dataset(data_path, class_name, is_train=True, resize=input_size, cropsize=input_size)\n",
    "print(\"Number of training samples:\", len(train_ds))\n",
    "print(\"Train Batches :\", len(train_ds)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b25b4d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 83\n",
      "Test Batches : 10\n"
     ]
    }
   ],
   "source": [
    "test_ds=MVTEC_Dataset(data_path, class_name, is_train=False, resize=input_size, cropsize=input_size)\n",
    "print(\"Number of test samples:\", len(test_ds))\n",
    "print(\"Test Batches :\", len(test_ds)//batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
